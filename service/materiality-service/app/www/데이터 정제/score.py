# -*- coding: utf-8 -*-
import re
import pandas as pd
from html import unescape
from email.utils import parsedate_to_datetime
from datetime import timezone

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# HTML íƒœê·¸ ì œê±° ë° ì—”í‹°í‹° í•´ì œ
def strip_html(text: str) -> str:
    if pd.isna(text):
        return ""
    s = str(text)
    s = re.sub(r'<\s*br\s*/?>', ' ', s, flags=re.I)  # <br> â†’ ê³µë°±
    s = re.sub(r'<[^>]+>', '', s)   # ëª¨ë“  íƒœê·¸ ì œê±°
    s = unescape(s)                 # &quot; ë“± ì—”í‹°í‹° í•´ì œ
    s = re.sub(r'\s+', ' ', s).strip()
    return s

# â–³/â–² ê¸°í˜¸ëŠ” ë‚¨ê¸°ê³  ì •ê·œí™”
def norm_keep_triangles(text: str) -> str:
    s = strip_html(text).lower()
    s = re.sub(r'[^ê°€-íž£a-z0-9â–³â–²]', '', s)
    return s

# ì¼ë°˜ ì •ê·œí™”(ì˜ë¬¸+í•œê¸€)
def norm_plain(text: str) -> str:
    s = strip_html(text).lower()
    s = re.sub(r'[^ê°€-íž£a-z0-9]', '', s)
    return s

# í•œê¸€ë§Œ ì¶”ì¶œ
def korean_only(text: str) -> str:
    s = strip_html(text).lower()
    return re.sub(r'[^ê°€-íž£]', '', s)

# â–³/â–² ë’¤ì— íšŒì‚¬ëª…ì´ ë‚˜ì˜¤ë©´ True (í˜¼í•©í‘œê¸° ì‹œ í•œê¸€ë§Œ ì¼ì¹˜ë„ í—ˆìš©)
def has_triangle_then_company(desc: str, company: str) -> bool:
    d = norm_keep_triangles(desc)
    comp_norm = norm_plain(company)
    comp_kor  = korean_only(company)

    targets = []
    if comp_norm:
        targets.append(re.escape(comp_norm))
    if comp_kor and comp_kor != comp_norm:
        targets.append(re.escape(comp_kor))

    # for t in targets:
    #     pattern = rf'[â–³â–²][^â–³â–²]*{t}'  # â–³/â–² ì´í›„ ë‹¤ìŒ â–³/â–² ì „ê¹Œì§€ íšŒì‚¬ëª…
    #     if re.search(pattern, d):
    #         return True
    return False

# pubDate ì´ˆê°•ë ¥ íŒŒì„œ
def robust_parse_pubdate(x):
    if x is None or (isinstance(x, float) and pd.isna(x)) or (isinstance(x, str) and x.strip() == ""):
        return pd.NaT
    if isinstance(x, pd.Timestamp):
        return x.tz_localize("UTC") if x.tzinfo is None else x.tz_convert("UTC")
    if isinstance(x, (int, float)) and not pd.isna(x):
        v = float(x)
        try:
            if v > 1e11:  # epoch ms
                return pd.to_datetime(int(v), unit="ms", utc=True)
            if v > 1e9:   # epoch s
                return pd.to_datetime(int(v), unit="s", utc=True)
            if 20000 < v < 60000:  # excel serial
                return pd.to_datetime(v, unit="D", origin="1899-12-30", utc=True)
        except Exception:
            pass
    s = str(x).strip()
    s = re.sub(r'\b(KST|JST|GMT\+9|GMT\+09:00)\b', '+0900', s, flags=re.I)
    ts = pd.to_datetime(s, errors="coerce", utc=True)
    if not pd.isna(ts):
        return ts
    try:
        dt = parsedate_to_datetime(s)
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        return pd.Timestamp(dt).tz_convert("UTC")
    except Exception:
        return pd.NaT

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    file_path = "../media_crawling/2023,2022ë…„ ì¤‘ëŒ€ì„±í‰ê°€ ëª©ë¡ ê¸°ë°˜ ë‰´ìŠ¤ë°ì´í„°(ì¤‘ë³µí—ˆìš©).xlsx"
    df = pd.read_excel(file_path)

    # íƒœê·¸ ì œê±°
    for col in ["title", "description", "company"]:
        if col in df.columns:
            df[col] = df[col].apply(strip_html)

    # news_score: ì œëª©ì— íšŒì‚¬ëª…ì´ í¬í•¨ë˜ë©´ "+"
    if "news_score" not in df.columns:
        df["news_score"] = ""
    else:
        df["news_score"] = df["news_score"].fillna("").astype(str)

    title_norm = df["title"].apply(lambda x: re.sub(r'[^ê°€-íž£a-z0-9]', '', strip_html(str(x)).lower()))
    company_norm = df["company"].apply(lambda x: re.sub(r'[^ê°€-íž£a-z0-9]', '', strip_html(str(x)).lower()))
    mask_title_contains_company = df.apply(
        lambda r: (r.get("company", "") != "") and (company_norm.loc[r.name] in title_norm.loc[r.name]),
        axis=1
    )
    df.loc[mask_title_contains_company, "news_score"] = "+"

    # description: â–³/â–² ë’¤ì— íšŒì‚¬ëª…ì´(í•œê¸€ë§Œ ì¼ì¹˜ í¬í•¨) ìžˆìœ¼ë©´ í–‰ ì‚­ì œ
    mask_drop = df.apply(lambda r: has_triangle_then_company(r.get("description", ""), r.get("company", "")), axis=1)
    df = df[~mask_drop].copy()

    # ë¶ˆìš© í‚¤ì›Œë“œ ê¸°ì‚¬ ì‚­ì œ
    keywords = ["ì£¼ì‹", "ì£¼ê°€", "ë§¤ìˆ˜", "ê´€ë ¨ì£¼"]
    pattern = "|".join(keywords)
    if "description" in df.columns:
        df = df[~df["description"].str.contains(pattern, case=False, na=False)]
    if "title" in df.columns:
        df = df[~df["title"].str.contains(pattern, case=False, na=False)]

    # recent_score: ê¸°ì¤€ì¼ ì„¤ì •
    df["pub_dt_utc"] = df.get("pubDate", pd.Series([None]*len(df))).apply(robust_parse_pubdate)

    # âœ… ê¸°ì¤€ì¼ ìžë™: ë°ì´í„°ì…‹ ë‚´ pubDateì˜ ìµœëŒ“ê°’(=ê²€ìƒ‰ ê¸°ì¤€ì¼ ê°€ì •)
    latest = df["pub_dt_utc"].max()
    if pd.isna(latest):
        # ëª¨ë‘ ì‹¤íŒ¨í•˜ë©´ ì˜¤ëŠ˜ë¡œ
        reference_date = pd.Timestamp.now(tz="Asia/Seoul").normalize()
    else:
        reference_date = latest.tz_convert("Asia/Seoul")

    # ðŸ‘‰ íŠ¹ì • ë‚ ì§œë¡œ ê³ ì •í•˜ê³  ì‹¶ìœ¼ë©´ ì´ í•œ ì¤„ë§Œ ì‚¬ìš©í•˜ì„¸ìš”:
    # reference_date = pd.Timestamp("2023-12-31 00:00:00", tz="Asia/Seoul")

    ref_utc = reference_date.tz_convert("UTC")

    # íŒŒì‹±/ê¸°ì¤€ì¼ ë¡œê·¸
    total_rows = len(df)
    parsed_ok = df["pub_dt_utc"].notna().sum()
    print(f"[recent_score] rows: {total_rows}, parsed OK: {parsed_ok}, failed: {total_rows - parsed_ok}")
    print(f"[recent_score] min pubDate: {df['pub_dt_utc'].min()}")
    print(f"[recent_score] max pubDate: {df['pub_dt_utc'].max()}")
    print(f"[recent_score] reference_date(Asia/Seoul): {reference_date}")

    # ì ìˆ˜ ê³„ì‚°(ì¼ìˆ˜ ê¸°ì¤€: 3ê°œì›”â‰ˆ92ì¼, 6ê°œì›”â‰ˆ183ì¼)
    delta_days = (ref_utc - df["pub_dt_utc"]).dt.days
    df["recent_score"] = ""
    df.loc[delta_days.notna() & (delta_days <= 92), "recent_score"] = "++"
    df.loc[delta_days.notna() & (92 < delta_days) & (delta_days <= 183), "recent_score"] = "+"

    # ì €ìž¥
    output_path = "ë‰´ìŠ¤ì¤‘ë³µë°ì´í„°_ê°€ê³µê²°ê³¼2.xlsx"
    df = df.drop(columns=["pub_dt_utc"], errors="ignore")
    df.to_excel(output_path, index=False)
    print(f"âœ… ì™„ë£Œ: {output_path}")
